@misc{ravindran2017cartpole,
      title={Methods of introducing noise to the CartPole environment in OpenAI Gym}, 
      author={Aaditya Ravindran},
      publisher={GitHub},
      journal={GitHub repository},
      year={2017},
      howpublished={\url{https://github.com/AadityaRavindran/gym-cartpolemod}}
}

@misc{robey2020modelbased,
      title={Model-Based Robust Deep Learning: Generalizing to Natural, Out-of-Distribution Data}, 
      author={Alexander Robey and Hamed Hassani and George J. Pappas},
      year={2020},
      eprint={2005.10247},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wu2021uncertaintyaware,
      title={Uncertainty-Aware Model-Based Reinforcement Learning with Application to Autonomous Driving}, 
      author={Jingda Wu and Zhiyu Huang and Chen Lv},
      year={2021},
      eprint={2106.12194},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

@misc{highway-env,
  author = {Leurent, Edouard},
  title = {An Environment for Autonomous Driving Decision-Making},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/eleurent/highway-env}}
}

@misc{khraishi2023simple,
      title={Simple Noisy Environment Augmentation for Reinforcement Learning}, 
      author={Raad Khraishi and Ramin Okhrati},
      year={2023},
      eprint={2305.02882},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wiki:snr,
   author = "Wikipedia",
   title = "{Signal-to-noise ratio} --- {W}ikipedia{,} The Free Encyclopedia",
   year = "2023",
   howpublished = {\url{http://en.wikipedia.org/w/index.php?title=Signal-to-noise%20ratio&oldid=1184390748}},
   note = "[Online; accessed 28-November-2023]"
}

@misc{nado2022uncertainty,
      title={Unvertainty Baselines: Benchmarks for Uncertainty \& Robustness in Deep Learning},
      author={Zachary Nado and Neil Band and Mark Collier and Josip Djolonga and Michael W. Dusenberry and Sebastian Farquhar and Qixuan Feng and Angelos Filos and Marton Havasi and Rodolphe Jenatton and Ghassen Jerfel and Jeremiah Liu and Zelda Mariet and Jeremy Nixon and Shreyas Padhy and Jie Ren and Tim G. J. Rudner and Faris Sbahi and Yeming Wen and Florian Wenzel and Kevin Murphy and D. Sculley and Balaji Lakshminarayanan and Jasper Snoek and Yarin Gal and Dustin Tran},
      year={2022},
      eprint={2106.04015},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{Rana_2021,
   title={Building Safer Autonomous Agents by Leveraging Risky Driving Behavior Knowledge},
   url={http://dx.doi.org/10.1109/CCCI52664.2021.9583209},
   DOI={10.1109/ccci52664.2021.9583209},
   booktitle={2021 International Conference on Communications, Computing, Cybersecurity, and Informatics (CCCI)},
   publisher={IEEE},
   author={Rana, Ashish and Malhi, Avleen},
   year={2021},
   month=oct 
}

@inproceedings{nyberg2021safetyspec,
      author={Nyberg, T. and Pek, C. and Dal Col, L. and Norén, C. and Tumova, J.},
      title={Risk-aware Motion Planning for Autonomous Vehicles with Safety Specifications},
      year={2021},
      url={https://kth.diva-portal.org/smash/record.jsf?pid=diva2:1558342&dswid=-2005},
      DOI={10.1109/IV48863.2021.9575928},
      booktitle={2021 32nd IEEE Intelligent Vehicles Symposium (IV)},
      publisher={IEEE},
      month={May}
}

@misc{shalevshwartz2016safe,
      title={Safe, Multi-Agent, Reinforcement Learning for Autonomous Driving}, 
      author={Shai Shalev-Shwartz and Shaked Shammah and Amnon Shashua},
      year={2016},
      eprint={1610.03295},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{dalal2018safe,
      title={Safe Exploration in Continuous Action Spaces}, 
      author={Gal Dalal and Krishnamurthy Dvijotham and Matej Vecerik and Todd Hester and Cosmin Paduraru and Yuval Tassa},
      year={2018},
      eprint={1801.08757},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{berkenkamp2017safe,
      title={Safe Model-based Reinforcement Learning with Stability Guarantees}, 
      author={Felix Berkenkamp and Matteo Turchetta and Angela P. Schoellig and Andreas Krause},
      year={2017},
      eprint={1705.08551},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{10.1145/3563357.3564055,
author = {Mottahedi, Sam and Pavlak, Gregory S.},
title = {Constrained Differentiable Cross-Entropy Method for Safe Model-Based Reinforcement Learning},
year = {2022},
isbn = {9781450398909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563357.3564055},
doi = {10.1145/3563357.3564055},
abstract = {Reinforcement learning agents must explore their environments to learn optimal policies through trial and error. Due to challenges in simulating the complexities of the real world, there is a growing trend of training reinforcement learning (RL) agents directly in the real world instead of mostly or entirely in simulation. Safety concerns are paramount when training RL agents directly in the real world. This paper proposes MPC-CDCEM, a model-based reinforcement algorithm (RL) that allows the agent to safely interact with the environment and explore without additional assumptions on system dynamics. The algorithm uses a Model Predictive Control (MPC) framework with a differentiable cross-entropy optimizer, which induces a differentiable policy that considers the constraints while addressing the objective mismatch problem in model-based RL algorithms. We evaluate our algorithm in Safety Gym environments and on a practical building energy optimization problem. In addition, we showed that in both experiments, our algorithms have the lowest number of constraint violations and achieve comparable rewards compared to baseline constrained RL algorithms.},
booktitle = {Proceedings of the 9th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {40–48},
numpages = {9},
keywords = {reinforcement learning, constrained Markov decision process, differentiable convex optimization, limited multi-label classification, cross-entropy methods},
location = {Boston, Massachusetts},
series = {BuildSys '22}
}

@misc{leurent2019approximate,
      title={Approximate Robust Control of Uncertain Dynamical Systems}, 
      author={Edouard Leurent and Yann Blanco and Denis Efimov and Odalric-Ambrym Maillard},
      year={2019},
      eprint={1903.00220},
      archivePrefix={arXiv},
      primaryClass={cs.SY}
}

@misc{liu2022simple,
      title={A Simple Approach to Improve Single-Model Deep Uncertainty via Distance-Awareness}, 
      author={Jeremiah Zhe Liu and Shreyas Padhy and Jie Ren and Zi Lin and Yeming Wen and Ghassen Jerfel and Zack Nado and Jasper Snoek and Dustin Tran and Balaji Lakshminarayanan},
      year={2022},
      eprint={2205.00403},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{salimbeni2017doubly,
      title={Doubly Stochastic Variational Inference for Deep Gaussian Processes}, 
      author={Hugh Salimbeni and Marc Deisenroth},
      year={2017},
      eprint={1705.08933},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{liu2021constrained,
      title={Constrained Model-based Reinforcement Learning with Robust Cross-Entropy Method}, 
      author={Zuxin Liu and Hongyi Zhou and Baiming Chen and Sicheng Zhong and Martial Hebert and Ding Zhao},
      year={2021},
      eprint={2010.07968},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{NEURIPS2018_34ffeb35,
 author = {Wen, Min and Topcu, Ufuk},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Constrained Cross-Entropy Method for Safe Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/34ffeb359a192eb8174b6854643cc046-Paper.pdf},
 volume = {31},
 year = {2018}
}